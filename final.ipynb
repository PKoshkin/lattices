{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = read_file(\"adult.data.txt\")\n",
    "raw_test = read_file(\"adult.test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_positive_target_rate = get_average_positive_target_rate(raw_train)\n",
    "X_train, Y_train = make_dataset(raw_train, average_positive_target_rate)\n",
    "X_train, Y_train = unique_dataset(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15210, 75), (15210,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7000\n",
    "test_size = 500\n",
    "permupation = np.random.permutation(len(X_train))\n",
    "train_indices = permupation[:train_size]\n",
    "test_indices = permupation[train_size:(train_size + test_size)]\n",
    "\n",
    "train_x = X_train[train_indices]\n",
    "train_y = Y_train[train_indices]\n",
    "test_x = X_train[test_indices]\n",
    "test_y = Y_train[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kfold(X, Y, folds):\n",
    "    kf = KFold(n_splits=folds)\n",
    "    metrics = []\n",
    "    stats = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        train_x, test_x = X[train_index], X[test_index]\n",
    "        train_y, test_y = Y[train_index], Y[test_index]\n",
    "        new_metrics = []\n",
    "        new_metrics.append(get_catboost_acc(train_x, train_y, test_x, test_y))\n",
    "        \n",
    "        pos_stats, neg_stats = lattices_stats(train_x, train_y, test_x)\n",
    "\n",
    "        stats.append((pos_stats, neg_stats))\n",
    "        \n",
    "        prediction_0 = [\n",
    "            1 if pos_stat[0] > neg_stat[0] else 0\n",
    "            for pos_stat, neg_stat in zip(pos_stats, neg_stats)\n",
    "        ]\n",
    "        prediction_1 = [\n",
    "            1 if pos_stat[0] > neg_stat[0] else 0\n",
    "            for pos_stat, neg_stat in zip(pos_stats, neg_stats)\n",
    "        ]\n",
    "        prediction_2 = [\n",
    "            1 if pos_stat[0] > neg_stat[0] else 0\n",
    "            for pos_stat, neg_stat in zip(pos_stats, neg_stats)\n",
    "        ]\n",
    "        prediction_3 = [\n",
    "            1 if pos_stat.sum() > neg_stat.sum() else 0\n",
    "            for pos_stat, neg_stat in zip(pos_stats, neg_stats)\n",
    "        ]\n",
    "\n",
    "        new_metrics.append(accuracy_score(prediction_0, test_y))\n",
    "        new_metrics.append(accuracy_score(prediction_1, test_y))\n",
    "        new_metrics.append(accuracy_score(prediction_2, test_y))\n",
    "        new_metrics.append(accuracy_score(prediction_3, test_y))\n",
    "        new_metrics.append(accuracy_score(np.zeros_like(test_y), test_y))\n",
    "        \n",
    "        metrics.append(new_metrics)\n",
    "    return np.array(metrics), stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "metrics, stats = make_kfold(train_x, train_y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Ys = []\n",
    "kf = KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    test_Ys.append(train_y[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Ys[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_accs(stats, Y):\n",
    "    pos_stats, neg_stats = stats\n",
    "    prediction_0 = [\n",
    "        1 if pos_stat[0] > neg_stat[0] else 0\n",
    "        for pos_stat, neg_stat in zip(pos_stats, neg_stats)\n",
    "    ]\n",
    "    prediction_1 = [\n",
    "        1 if pos_stat[1] > neg_stat[1] else 0\n",
    "        for pos_stat, neg_stat in zip(pos_stats, neg_stats)\n",
    "    ]\n",
    "    prediction_2 = [\n",
    "        1 if pos_stat[2] > neg_stat[2] else 0\n",
    "        for pos_stat, neg_stat in zip(pos_stats, neg_stats)\n",
    "    ]\n",
    "    prediction_3 = [\n",
    "        1 if pos_stat.sum() > neg_stat.sum() else 0\n",
    "        for pos_stat, neg_stat in zip(pos_stats, neg_stats)\n",
    "    ]\n",
    "    metrics = [\n",
    "        accuracy_score(prediction_0, Y),\n",
    "        accuracy_score(prediction_1, Y),\n",
    "        accuracy_score(prediction_2, Y),\n",
    "        accuracy_score(prediction_3, Y),\n",
    "    ]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_accs(stats_list, Y_list):\n",
    "    metrics = []\n",
    "    for stats, Y in zip(stats_list, Y_list):\n",
    "        metrics.append(get_predictions_accs(stats, Y))\n",
    "    return np.array(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_metrics = get_all_accs(stats, test_Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87617823, 0.85946872, 0.85946872, 0.85946872, 0.85946872,\n",
       "        0.80891174],\n",
       "       [0.8752679 , 0.86583798, 0.86583798, 0.86583798, 0.86712387,\n",
       "        0.8084012 ],\n",
       "       [0.87183883, 0.85426489, 0.85426489, 0.85426489, 0.85597943,\n",
       "        0.79254179]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85946872, 0.83847472, 0.77720651, 0.85946872],\n",
       "       [0.86583798, 0.85212173, 0.77496785, 0.86712387],\n",
       "       [0.85426489, 0.83540506, 0.77453922, 0.85597943]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics = np.concatenate([metrics[:, :1], metrics[:, -1:], right_metrics], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87617823 0.80891174 0.85946872 0.83847472 0.77720651 0.85946872]\n",
      " [0.8752679  0.8084012  0.86583798 0.85212173 0.77496785 0.86712387]\n",
      " [0.87183883 0.79254179 0.85426489 0.83540506 0.77453922 0.85597943]]\n"
     ]
    }
   ],
   "source": [
    "print(result_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
